import unicodedata
from sqlalchemy.orm import Session, joinedload, aliased
from sqlalchemy import and_, desc, or_, func, text, exists, case
from typing import List, Optional, Dict, Any
from models import Paper, Author, PaperAuthor, Tag, PaperTag, Venue
from schemas import (
    PaperCreate, PaperUpdate, AuthorCreate, TagCreate, VenueCreate, SearchFilters, 
    ComplexSearchQuery, FilterGroup, FilterCondition
)

# Paper CRUD operations
def check_doi_exists(db: Session, doi: str) -> bool:
    """æª¢æŸ¥DOIæ˜¯å¦å·²å­˜åœ¨"""
    if not doi:
        return False
    return db.query(Paper).filter(Paper.doi == doi).first() is not None

def create_paper(db: Session, paper: PaperCreate):
    # æª¢æŸ¥DOIæ˜¯å¦å·²å­˜åœ¨
    if paper.doi and check_doi_exists(db, paper.doi):
        raise ValueError(f"DOI '{paper.doi}' å·²å­˜åœ¨")
    
    # å‰µå»ºè«–æ–‡è¨˜éŒ„
    db_paper = Paper(
        title=paper.title,
        abstract=paper.abstract,
        publication_year=paper.publication_year,
        doi=paper.doi,
        citation_count=paper.citation_count,
        venue_id=paper.venue_id,
        keywords=paper.keywords,
        url=paper.url,
        document_type=paper.document_type # æ–°å¢ document_type æ¬„ä½
    )
    db.add(db_paper)
    db.commit()
    db.refresh(db_paper)
    
    # æ·»åŠ ä½œè€…é—œè¯
    for i, author_id in enumerate(paper.author_ids):
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„é—œè¯
        existing_relation = db.query(PaperAuthor).filter(
            and_(PaperAuthor.paper_id == db_paper.id, PaperAuthor.author_id == author_id)
        ).first()
        
        if not existing_relation:
            paper_author = PaperAuthor(
                paper_id=db_paper.id,
                author_id=author_id,
                author_order=i + 1
            )
            db.add(paper_author)
    
    # æ·»åŠ æ¨™ç±¤é—œè¯
    for tag_id in paper.tag_ids:
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„é—œè¯
        existing_relation = db.query(PaperTag).filter(
            and_(PaperTag.paper_id == db_paper.id, PaperTag.tag_id == tag_id)
        ).first()
        
        if not existing_relation:
            paper_tag = PaperTag(paper_id=db_paper.id, tag_id=tag_id)
            db.add(paper_tag)
    
    db.commit()
    db.refresh(db_paper)
    return db_paper

def get_papers(db: Session, skip: int = 0, limit: int = 100):
    return db.query(Paper).options(
        joinedload(Paper.venue),
        joinedload(Paper.authors).joinedload(PaperAuthor.author),
        joinedload(Paper.tags).joinedload(PaperTag.tag)
    ).offset(skip).limit(limit).all()

def get_paper(db: Session, paper_id: int):
    return db.query(Paper).options(
        joinedload(Paper.venue),
        joinedload(Paper.authors).joinedload(PaperAuthor.author),
        joinedload(Paper.tags).joinedload(PaperTag.tag)
    ).filter(Paper.id == paper_id).first()

def get_year_distribution(db):
    results = (
        db.query(Paper.publication_year, func.count(Paper.id))
        .group_by(Paper.publication_year)
        .order_by(Paper.publication_year)
        .all()
    )
    return [
        {"year": year, "count": count}
        for year, count in results
        if year is not None
    ]

def get_venue_distribution(db: Session):
    # çµ±è¨ˆå‰15åæœŸåˆŠ/æœƒè­°
    result = db.query(
        Venue.name,
        Venue.type,
        Venue.impact_factor,
        func.count(Paper.id).label("count")
    ).join(Paper).group_by(Venue.id).order_by(desc("count")).limit(15).all()
    return [{"name": r.name, "type": r.type, "impact_factor": r.impact_factor, "count": r.count} for r in result]

def get_tag_distribution(db: Session):
    # çµ±è¨ˆå‰5åæ¨™ç±¤
    result = db.query(
        Tag.id,
        Tag.name,
        Tag.color,
        func.count(PaperTag.paper_id).label("count")
    ).join(PaperTag).group_by(Tag.id).order_by(desc("count")).limit(5).all()
    return [{"id": r.id, "name": r.name, "color": r.color, "count": r.count} for r in result]

def count_all_papers(db: Session) -> int:
    """è¨ˆç®—æ‰€æœ‰è«–æ–‡çš„ç¸½æ•¸"""
    return db.query(Paper).count()

def count_papers_with_tag(db: Session, tag_name: str) -> int:
    """è¨ˆç®—å…·æœ‰ç‰¹å®šæ¨™ç±¤çš„è«–æ–‡æ•¸é‡"""
    return db.query(Paper).join(PaperTag).join(Tag).filter(Tag.name == tag_name).count()

def update_paper(db: Session, paper_id: int, paper: PaperUpdate):
    db_paper = db.query(Paper).filter(Paper.id == paper_id).first()
    if not db_paper:
        return None
    
    # æ›´æ–°åŸºæœ¬å­—æ®µ
    for field, value in paper.model_dump(exclude_unset=True).items():
        if field not in ['author_ids', 'tag_ids'] and value is not None:
            setattr(db_paper, field, value)
    
    # æ›´æ–°ä½œè€…é—œè¯
    if paper.author_ids is not None:
        # åˆªé™¤ç¾æœ‰é—œè¯
        db.query(PaperAuthor).filter(PaperAuthor.paper_id == paper_id).delete()
        # æ·»åŠ æ–°é—œè¯
        for i, author_id in enumerate(paper.author_ids):
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„é—œè¯ï¼ˆé›–ç„¶ä¸Šé¢å·²åˆªé™¤ï¼Œä½†ç‚ºäº†é˜²éŒ¯ï¼‰
            existing_relation = db.query(PaperAuthor).filter(
                and_(PaperAuthor.paper_id == paper_id, PaperAuthor.author_id == author_id)
            ).first()
            
            if not existing_relation:
                paper_author = PaperAuthor(
                    paper_id=paper_id,
                    author_id=author_id,
                    author_order=i + 1
                )
                db.add(paper_author)
    
    # æ›´æ–°æ¨™ç±¤é—œè¯
    if paper.tag_ids is not None:
        # åˆªé™¤ç¾æœ‰é—œè¯
        db.query(PaperTag).filter(PaperTag.paper_id == paper_id).delete()
        # æ·»åŠ æ–°é—œè¯
        for tag_id in paper.tag_ids:
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„é—œè¯ï¼ˆé›–ç„¶ä¸Šé¢å·²åˆªé™¤ï¼Œä½†ç‚ºäº†é˜²éŒ¯ï¼‰
            existing_relation = db.query(PaperTag).filter(
                and_(PaperTag.paper_id == paper_id, PaperTag.tag_id == tag_id)
            ).first()
            
            if not existing_relation:
                paper_tag = PaperTag(paper_id=paper_id, tag_id=tag_id)
                db.add(paper_tag)
    
    db.commit()
    db.refresh(db_paper)
    return db_paper

def delete_paper(db: Session, paper_id: int):
    db_paper = db.query(Paper).filter(Paper.id == paper_id).first()
    if not db_paper:
        return False
    
    db.delete(db_paper)
    db.commit()
    return True

def search_papers(db: Session, filters: SearchFilters, skip: int = 0, limit: int = 100):
    """å¤šæ¢ä»¶æœç´¢è«–æ–‡"""
    query = db.query(Paper).options(
        joinedload(Paper.venue),
        joinedload(Paper.authors).joinedload(PaperAuthor.author),
        joinedload(Paper.tags).joinedload(PaperTag.tag)
    )
    
    conditions = []
    
    # æ¨™é¡Œé—œéµå­—æœç´¢ï¼ˆå…¨æ–‡æœç´¢ï¼‰
    if filters.title_keyword:
        conditions.append(
            func.to_tsvector('english', Paper.title).match(filters.title_keyword)
        )
    
    # æ‘˜è¦é—œéµå­—æœç´¢
    if filters.abstract_keyword:
        conditions.append(
            func.to_tsvector('english', Paper.abstract).match(filters.abstract_keyword)
        )
    
    # ä½œè€…å§“åæœç´¢
    if filters.author_name:
        query = query.join(PaperAuthor).join(Author)
        conditions.append(
            func.to_tsvector('english', Author.name).match(filters.author_name)
        )
    
    # å¹´ä»½ç¯„åœ
    if filters.year_from:
        conditions.append(Paper.publication_year >= filters.year_from)
    if filters.year_to:
        conditions.append(Paper.publication_year <= filters.year_to)
    
    # å¼•ç”¨æ•¸ç¯„åœ
    if filters.min_citations:
        conditions.append(Paper.citation_count >= filters.min_citations)
    if filters.max_citations:
        conditions.append(Paper.citation_count <= filters.max_citations)
    
    # æœŸåˆŠ/æœƒè­°
    if filters.venue_id:
        conditions.append(Paper.venue_id == filters.venue_id)
    
    # æ¨™ç±¤æœç´¢
    if filters.tags:
        query = query.join(PaperTag).join(Tag)
        conditions.append(Tag.name.in_(filters.tags))
    
    # æ‡‰ç”¨æ‰€æœ‰æ¢ä»¶
    if conditions:
        query = query.filter(and_(*conditions))
    
    return query.distinct().offset(skip).limit(limit).all()

def search_papers_complex(db: Session, query_data: ComplexSearchQuery, skip: int = 0, limit: int = 100):
    """è™•ç†è¤‡é›œçš„ AND/OR æœç´¢æŸ¥è©¢"""
    query = db.query(Paper).options(
        joinedload(Paper.venue),
        joinedload(Paper.authors).joinedload(PaperAuthor.author),
        joinedload(Paper.tags).joinedload(PaperTag.tag)
    )
    
    # æª¢æŸ¥æ˜¯å¦éœ€è¦ JOIN
    needs_author_join = check_needs_author_join(query_data.root)
    needs_tag_join = check_needs_tag_join(query_data.root)
    
    # æ·»åŠ å¿…è¦çš„ JOIN
    if needs_author_join:
        query = query.join(PaperAuthor).join(Author)
    
    if needs_tag_join:
        query = query.join(PaperTag).join(Tag)
    
    # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
    conditions = build_query_conditions(db, query_data.root)
    
    if conditions is not None:
        query = query.filter(conditions)
    
    return query.distinct().offset(skip).limit(limit).all()

def check_needs_author_join(group: FilterGroup) -> bool:
    """æª¢æŸ¥æ˜¯å¦éœ€è¦ author JOIN"""
    for condition in group.conditions:
        if condition.field == 'author_name':
            return True
    for subgroup in group.groups:
        if check_needs_author_join(subgroup):
            return True
    return False

def check_needs_tag_join(group: FilterGroup) -> bool:
    """æª¢æŸ¥æ˜¯å¦éœ€è¦ tag JOIN"""
    for condition in group.conditions:
        if condition.field == 'tags':
            return True
    for subgroup in group.groups:
        if check_needs_tag_join(subgroup):
            return True
    return False

def build_query_conditions(db: Session, group: FilterGroup):
    """éæ­¸æ§‹å»ºæŸ¥è©¢æ¢ä»¶"""
    conditions = []
    
    # è™•ç†ç•¶å‰ç¾¤çµ„çš„æ¢ä»¶
    for condition in group.conditions:
        db_condition = build_single_condition(condition)
        if db_condition is not None:
            conditions.append(db_condition)
    
    # éæ­¸è™•ç†å­ç¾¤çµ„
    for subgroup in group.groups:
        subgroup_condition = build_query_conditions(db, subgroup)
        if subgroup_condition is not None:
            conditions.append(subgroup_condition)
    
    if not conditions:
        return None
    
    # æ ¹æ“šæ“ä½œç¬¦çµ„åˆæ¢ä»¶
    if group.operator == 'AND':
        return and_(*conditions)
    else:  # OR
        return or_(*conditions)

def build_single_condition(condition: FilterCondition):
    """æ§‹å»ºå–®å€‹æœç´¢æ¢ä»¶"""
    field = condition.field
    operator = condition.operator
    value = condition.value
    
    # å¦‚æœå€¼ç‚ºç©ºï¼Œè·³éæ­¤æ¢ä»¶
    if not value or (isinstance(value, str) and value.strip() == ''):
        return None
    
    try:
        if field == 'title_keyword':
            if operator == 'contains':
                return Paper.title.ilike(f'%{str(value)}%')
            elif operator == 'equals':
                return Paper.title == str(value)
                
        elif field == 'abstract_keyword':
            if operator == 'contains':
                return Paper.abstract.ilike(f'%{str(value)}%')
            elif operator == 'equals':
                return Paper.abstract == str(value)
                
        elif field == 'author_name':
            if operator == 'contains':
                return Author.name.ilike(f'%{str(value)}%')
            elif operator == 'equals':
                return Author.name == str(value)
                
        elif field == 'year_from':
            if operator in ['greater_than', 'greater_equal']:
                return Paper.publication_year >= int(value)
            elif operator == 'equals':
                return Paper.publication_year == int(value)
                
        elif field == 'year_to':
            if operator in ['less_than', 'less_equal']:
                return Paper.publication_year <= int(value)
            elif operator == 'equals':
                return Paper.publication_year == int(value)
                
        elif field == 'min_citations':
            if operator in ['greater_than', 'greater_equal']:
                return Paper.citation_count >= int(value)
            elif operator == 'equals':
                return Paper.citation_count == int(value)
                
        elif field == 'max_citations':
            if operator in ['less_than', 'less_equal']:
                return Paper.citation_count <= int(value)
            elif operator == 'equals':
                return Paper.citation_count == int(value)
                
        elif field == 'venue_id':
            if operator == 'equals':
                return Paper.venue_id == int(value)
                
        elif field == 'tags':
            if operator == 'in' and isinstance(value, list):
                return Tag.name.in_(value)
            elif operator == 'equals':
                tag_value = value[0] if isinstance(value, list) else str(value)
                return Tag.name == tag_value
                
    except (ValueError, TypeError):
        # å¦‚æœé¡å‹è½‰æ›å¤±æ•—ï¼Œè·³éæ­¤æ¢ä»¶
        pass
    
    return None

# Author CRUD operations
def create_author(db: Session, author: AuthorCreate):
    db_author = Author(**author.model_dump())
    db.add(db_author)
    db.commit()
    db.refresh(db_author)
    return db_author

def get_authors(db: Session, skip: int = 0, limit: int = 100):
    return db.query(Author).offset(skip).limit(limit).all()

def get_author(db: Session, author_id: int):
    return db.query(Author).filter(Author.id == author_id).first()

# Tag CRUD operations
def create_tag(db: Session, tag: TagCreate):
    db_tag = Tag(**tag.model_dump())
    db.add(db_tag)
    db.commit()
    db.refresh(db_tag)
    return db_tag

def get_tags(db: Session):
    return db.query(Tag).all()

def get_tag(db: Session, tag_id: int):
    return db.query(Tag).filter(Tag.id == tag_id).first()

# Venue CRUD operations
def create_venue(db: Session, venue: VenueCreate):
    db_venue = Venue(**venue.model_dump())
    db.add(db_venue)
    db.commit()
    db.refresh(db_venue)
    return db_venue

def get_venues(db: Session):
    return db.query(Venue).all()

def get_venue(db: Session, venue_id: int):
    return db.query(Venue).filter(Venue.id == venue_id).first()

# æ‰¹é‡æ¨™ç±¤æ“ä½œ
def batch_add_tags_to_papers(db: Session, paper_ids: List[int], tag_ids: List[int]):
    """æ‰¹é‡ç‚ºè«–æ–‡æ·»åŠ æ¨™ç±¤"""
    from schemas import BatchTagResult
    
    success_count = 0
    error_count = 0
    updated_paper_ids = []
    errors = []
    
    try:
        # é©—è­‰è«–æ–‡å­˜åœ¨
        existing_papers = db.query(Paper.id).filter(Paper.id.in_(paper_ids)).all()
        existing_paper_ids = [p.id for p in existing_papers]
        
        # é©—è­‰æ¨™ç±¤å­˜åœ¨
        existing_tags = db.query(Tag.id).filter(Tag.id.in_(tag_ids)).all()
        existing_tag_ids = [t.id for t in existing_tags]
        
        if not existing_tag_ids:
            errors.append("æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ¨™ç±¤")
            return BatchTagResult(
                success_count=0,
                error_count=len(paper_ids),
                updated_paper_ids=[],
                errors=errors
            )
        
        for paper_id in existing_paper_ids:
            try:
                for tag_id in existing_tag_ids:
                    # æª¢æŸ¥é—œè¯æ˜¯å¦å·²å­˜åœ¨
                    existing_relation = db.query(PaperTag).filter(
                        PaperTag.paper_id == paper_id,
                        PaperTag.tag_id == tag_id
                    ).first()
                    
                    if not existing_relation:
                        paper_tag = PaperTag(paper_id=paper_id, tag_id=tag_id)
                        db.add(paper_tag)
                
                success_count += 1
                updated_paper_ids.append(paper_id)
                
            except Exception as e:
                error_count += 1
                errors.append(f"è«–æ–‡ {paper_id} æ·»åŠ æ¨™ç±¤å¤±æ•—: {str(e)}")
        
        db.commit()
        
    except Exception as e:
        db.rollback()
        errors.append(f"æ‰¹é‡æ“ä½œå¤±æ•—: {str(e)}")
        error_count = len(paper_ids)
        success_count = 0
        updated_paper_ids = []
    
    return BatchTagResult(
        success_count=success_count,
        error_count=error_count,
        updated_paper_ids=updated_paper_ids,
        errors=errors
    )

def batch_remove_tags_from_papers(db: Session, paper_ids: List[int], tag_ids: List[int]):
    """æ‰¹é‡å¾è«–æ–‡ä¸­ç§»é™¤æ¨™ç±¤"""
    from schemas import BatchTagResult
    
    success_count = 0
    error_count = 0
    updated_paper_ids = []
    errors = []
    
    try:
        for paper_id in paper_ids:
            try:
                # åˆªé™¤æŒ‡å®šçš„æ¨™ç±¤é—œè¯
                deleted_count = db.query(PaperTag).filter(
                    PaperTag.paper_id == paper_id,
                    PaperTag.tag_id.in_(tag_ids)
                ).delete(synchronize_session=False)
                
                if deleted_count > 0:
                    success_count += 1
                    updated_paper_ids.append(paper_id)
                
            except Exception as e:
                error_count += 1
                errors.append(f"è«–æ–‡ {paper_id} ç§»é™¤æ¨™ç±¤å¤±æ•—: {str(e)}")
        
        db.commit()
        
    except Exception as e:
        db.rollback()
        errors.append(f"æ‰¹é‡æ“ä½œå¤±æ•—: {str(e)}")
        error_count = len(paper_ids)
        success_count = 0
        updated_paper_ids = []
    
    return BatchTagResult(
        success_count=success_count,
        error_count=error_count,
        updated_paper_ids=updated_paper_ids,
        errors=errors
    ) 

def normalize_text(s: str):
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s)
    s = s.replace("\u00a0", " ").replace("\u202f", " ")
    s = " ".join(s.split())  # ç§»é™¤å¤šé¤˜ç©ºç™½
    return s.strip().lower()


def search_related_papers(db: Session, paper_data: PaperCreate, limit: int = 5):
    # (0) DOI ç²¾æº–åŒ¹é…
    if paper_data.doi:
        doi_clean = paper_data.doi.strip().lower()
        exists = (
            db.query(Paper)
            .filter(func.lower(Paper.doi) == doi_clean)
            .options(joinedload(Paper.authors).joinedload(PaperAuthor.author))
            .first()
        )
        if exists:
            return [exists]

    # (1) æ¨™é¡Œæ¯”å°
    title_norm = normalize_text(paper_data.title)

    # ä½¿ç”¨ PostgreSQL LOWER + REPLACE æ¸…æ´—è³‡æ–™åº«å­—ä¸²
    db_title_norm = func.lower(
        func.replace(
            func.replace(
                func.replace(Paper.title, "\u00a0", " "),
                "\u202f",
                " "
            ),
            "  ",
            " "
        )
    )

    # ç²¾æº–åŒ¹é…ï¼ˆå°‡é›™ç©ºç™½è®Šå–®ç©ºç™½ï¼‰
    exact = db_title_norm == title_norm

    # æ¨¡ç³ŠåŒ¹é…ï¼ˆä¸å†ç”¨ %lowered_title%ï¼‰
    fuzzy = db_title_norm.ilike(f"%{title_norm[:20]}%")  # å‰20å­—å¼·åŒ¹é…

    query = (
        db.query(Paper)
        .options(joinedload(Paper.authors).joinedload(PaperAuthor.author))
        .filter(or_(exact, fuzzy))
    )

    results = query.distinct().limit(limit).all()

    if results:
        return results

    # fallback
    return db.query(Paper).limit(limit).all()

# def search_related_papers(db: Session, paper_data: PaperCreate, limit: int = 5):
#     """
#     æ ¹æ“šæ–°è³‡æºçš„å…ƒæ•¸æ“š (DOIã€æ¨™é¡Œã€ä½œè€…ã€é—œéµå­—) æœç´¢æ½›åœ¨ç›¸é—œçš„ç¾æœ‰è³‡æºã€‚
#     é‡é»ï¼š
#     - æ°¸é å„ªå…ˆåŸ·è¡Œ DOI ç²¾æº–æ¯”å°ï¼ˆç¦æ­¢ missï¼‰
#     - Title åš Unicode æ­£è¦åŒ– + åš´æ ¼èˆ‡é¬†æ•£æ¯”å°
#     - ä½œè€…èˆ‡é—œéµå­—ä½œç‚ºè¼”åŠ©
#     """

#     # ---------------------------------------------------------
#     # ğŸ” (0) DOI ç²¾æº–åŒ¹é… â€” æ°¸é ç¬¬ä¸€é †ä½ï¼Œä¸”ä¸æœƒ fail
#     # ---------------------------------------------------------
#     if paper_data.doi:
#         exists = (
#             db.query(Paper)
#             .filter(func.lower(Paper.doi) == paper_data.doi.strip().lower())
#             .options(
#                 joinedload(Paper.authors).joinedload(PaperAuthor.author),
#                 joinedload(Paper.tags).joinedload(PaperTag.tag)
#             )
#             .first()
#         )
#         if exists:
#             # è‹¥ DOI å·²å­˜åœ¨ â†’ ç›´æ¥å›å‚³è©²ç­†
#             return [exists]

#     # ---------------------------------------------------------
#     # åŸºç¤ queryï¼šé™åˆ¶ Paper é¡å‹
#     # ---------------------------------------------------------
#     query = (
#         db.query(Paper)
#         .options(
#             joinedload(Paper.authors).joinedload(PaperAuthor.author),
#             joinedload(Paper.tags).joinedload(PaperTag.tag)
#         )
#     )

#     conditions = []

#     # ---------------------------------------------------------
#     # (1) æ¨™é¡Œæ¯”å°ï¼šUnicode æ­£è¦åŒ– + ç²¾æº– + æ¨¡ç³Š
#     # ---------------------------------------------------------
#     if paper_data.title:
#         raw_title = paper_data.title

#         # Unicode æ­£è¦åŒ–ï¼ˆå¿…è¦è™•ç†ï¼‰
#         normalized = unicodedata.normalize("NFC", raw_title)

#         # æ›¿æ›ä¸å¸¸è¦‹ç©ºç™½ç¬¦
#         clean_title = (
#             normalized.replace("\u00a0", " ")
#             .replace("\u202f", " ")
#             .strip()
#             .lower()
#         )

#         if clean_title:
#             # title ç²¾æº–åŒ¹é…ï¼ˆlower + trimï¼‰
#             exact_title = func.lower(func.trim(Paper.title)) == clean_title

#             # æ¨¡ç³ŠåŒ¹é…
#             fuzzy_title = Paper.title.ilike(f"%{clean_title}%")

#             conditions.append(or_(exact_title, fuzzy_title))

#     # ---------------------------------------------------------
#     # (2) ä½œè€…æ¯”å°ï¼šä»»ä½•ä¸€ä½ä½œè€…å‘½ä¸­å°±ç®—ç›¸é—œ
#     # ---------------------------------------------------------
#     if getattr(paper_data, "author_names", None):
#         author_keys = [
#             k.strip().lower()
#             for k in paper_data.author_names.split(",")
#             if k.strip()
#         ]
#         if author_keys:
#             query = query.join(PaperAuthor).join(Author)
#             author_conditions = [
#                 func.lower(Author.name).ilike(f"%{k}%") for k in author_keys
#             ]
#             conditions.append(or_(*author_conditions))

#     # ---------------------------------------------------------
#     # (3) é—œéµå­—æ¯”å°ï¼šæ¨™é¡Œ/æ‘˜è¦æ¨¡ç³ŠæŸ¥è©¢
#     # ---------------------------------------------------------
#     if paper_data.keywords and isinstance(paper_data.keywords, list):
#         kw_conditions = []
#         for kw in paper_data.keywords:
#             if kw:
#                 kw_conditions.append(Paper.title.ilike(f"%{kw}%"))
#                 kw_conditions.append(Paper.abstract.ilike(f"%{kw}%"))

#         if kw_conditions:
#             conditions.append(or_(*kw_conditions))

#     # ---------------------------------------------------------
#     # (4) åˆä½µæ¢ä»¶
#     # ---------------------------------------------------------
#     if conditions:
#         query = query.filter(or_(*conditions))

#     results = query.distinct().limit(limit).all()

#     # ---------------------------------------------------------
#     # (5) fallbackï¼šè‡³å°‘å›å‚³ limit ç­† â†’ è®“ Step 4 ä¸€å®šæœƒåŸ·è¡Œ
#     # ---------------------------------------------------------
#     if not results:
#         results = (
#             db.query(Paper)
#             .limit(limit)
#             .all()
#         )

#     return results

def merge_paper(db: Session, paper_id: int, new_data: PaperCreate, mode: str, fields: List[str] = None):
    paper = db.query(Paper).filter(Paper.id == paper_id).first()
    if not paper:
        return None

    if mode == "keep_old":
        return paper

    if mode == "overwrite":
        # ç›´æ¥è¦†è“‹ï¼ˆå®Œæ•´æ›´æ–°ï¼‰
        update = PaperUpdate(**new_data.model_dump())
        return update_paper(db, paper_id, update)

    if mode == "merge_fields":
        if not fields:
            return paper
        
        update_dict = {}
        raw = new_data.model_dump()

        for f in fields:
            if f in raw:
                update_dict[f] = raw[f]

        update = PaperUpdate(**update_dict)
        return update_paper(db, paper_id, update)

    return paper